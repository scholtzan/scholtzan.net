+++
title = "Speeding up Mozilla's automatic experiment analysis"
date = "2020-12-04"
type = "post"
tags = ["Mozilla", "Open Source", "Argo", "Python", "Jetstream", "Dask"]
+++

_This post describes my recent work on [jetstream](https://github.com/mozilla/jetstream) as part of my day job at Mozilla. In particular, I'll describe how [Argo](https://argoproj.github.io/) and [Dask](https://dask.org/) were used to scale up a system that processes data dozens of different [experiments](https://firefox-source-docs.mozilla.org/browser/urlbar/experiments.html#experiments) in Firefox daily and on-demand. This work has been co-developed with my colleague [Tim Smith](https://github.com/tdsmith)._

Beginning of 2020 the development of a new experiment analysis infrastructure was launched at Mozilla which should help scaling up the number of experiments done in Firefox and reduce the involvement of data scientists necessary for each experiment.
The entire infrastructure consists of different components and services, with [jetstream](https://github.com/mozilla/jetstream) being the component that automatically analyses collected telemetry data of clients enrolled in experiments. As the number of experiments started to increase, some of which require processing an extensive amount of data, running the daily automatic analyses started to take very long. In some cases completing the experiment analyses for a single day took over 23 hours. To provide analysis results without significant delay and speed up the entire analysis process, it was time to make some architectural changes and parallelize jetstream's experiment analysis. [Argo](https://argoproj.github.io/) looked perfect for parallelizing the analysis on a higher level and in combination with [Dask](https://dask.org/) for parallelizing lower-level calculations, we were able to significantly reduce the analysis runtime.


# Background: jetstream

![Jetstream Overview](/img/jetstream-overview.png)
*Jetstream Overview.*

At Mozilla, experiments are managed by the [Experimenter](https://github.com/mozilla/experimenter) service and delivered to Firefox clients via [Normandy](https://mozilla.github.io/normandy). Product stakeholders and data scientists are interested in how specific metrics, such as the number of hours Firefox has been used or number of searches done, are affected by these experiments. Jetstream is [scheduled in Airflow](https://github.com/mozilla/telemetry-airflow/blob/master/dags/jetstream.py) to calculate metrics and apply statistical treatments to collected experiment [telemetry data](https://docs.telemetry.mozilla.org/tools/guiding_principles.html) for different analysis windows. Our telemetry data as well as all of the generated data artefacts are stored in [BigQuery](https://cloud.google.com/bigquery). 

The generated data artefacts are visualized in dashboards that allow stakeholders to see results and changes. Data scientists have direct access to the datasets generated by jetstream to allow for custom analysis. For calculating metrics and statistics jetstream uses the [mozanalysis library](https://github.com/mozilla/mozanalysis) Python library.
While there are a few [pre-defined metrics and statistics](https://github.com/mozilla/jetstream/tree/main/jetstream/config) that are calculated for every experiment, it is also possible to provide custom configurations with additional metrics and statistics. These configurations are stored in the [jetstream-config repository](https://github.com/mozilla/jetstream-config) and automatically detected and applied by jetstream. A more detailed architectural overview of jetstream and how it fits in the experiment analysis infrastructure is available in the [repository Wiki](https://github.com/mozilla/jetstream/wiki/Architecture).

When analyzing experiments, the following steps are executed for each experiment:

![Jetstream Analysis Steps](https://raw.githubusercontent.com/mozilla/jetstream/main/docs/analysis-steps.png)
*Jetstream experiment analysis steps.*

A default configuration and, if defined, a custom configuration provided via the [jetstream-config repository](https://github.com/mozilla/jetstream-config) are parsed and used for analysis. The experiment definition and config parameters are used to run some checks to determine if the experiment can be analyzed. These checks include, for example, validating start dates, end dates and enrollment periods.

If the experiment is valid, then metrics are calculated for each analysis period (daily, weekly, overall) and written to BigQuery. Metrics are either specified or a reference to existing metrics defined in mozanalysis is provided in the configuration files. Next, for each segment, first pre-treatments are applied to the metrics data which is then used to calculate statistics. Statistics data is written to BigQuery and later exported to GCS as JSON.

Initially, jetstream was set up to run on Airflow, constraining it to a single slot with limited amount of memory available which was limiting the analysis speed. For each of these experiments, up to 12 GB of memory are required to calculate statistics. As the number of experiments analyses per day increased simply running the analyses of these experiments in a single Kubernetes pod was not performant anymore. As Airflow does not support creating tasks dynamically during runtime, it was not possible to create separate tasks for each experiment analysis. A different approach as needed.


# Parallelizing experiment analyses using Argo



Argo is a light-weight workflow engine for orchestrating parallel jobs on Kubernetes and is capable of creating tasks dynamically that will be executed in parallel. Some preliminary experiments indicate that Argo is a good fit for distributing analyses for different experiments.





* solution
	* setup
	* Argo
		* some general information
		* workflows
		* python client
		* benchmmarks
		* dashboard
	* Dask
		* some general information
		* adding Dask
			* rewriting without nesting
			* pickle problems
		* benchmakrs
* error handling?
	* bigquery logging
* pain points
	* permissions
* future work
	* dask kubernetes